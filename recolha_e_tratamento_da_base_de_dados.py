# -*- coding: utf-8 -*-
"""Recolha e tratamento da base de dados.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yA31c2_KOf40XafZNfq8Ztw0NN8M_gBY

## Import libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""# 1.Dataset"""

dataset_airbnb =pd.read_csv("http://data.insideairbnb.com/portugal/lisbon/lisbon/2022-09-13/data/listings.csv.gz")

dataset_airbnb.head()

dataset_airbnb.info()

"""# 2. Pre-processamento do Dataset"""

# Dimensão do Dataset
print(f'number of rows: {dataset_airbnb.shape[0]}')
print(f'number of columns: {dataset_airbnb.shape[1]}')

# Visualizar os tipos de dados de cada coluna
dataset_airbnb.dtypes

# Criar um DataFrame com valores nulos, tipos de dados e contagem de valores únicos
nulos = pd.DataFrame({
    'null_values': dataset_airbnb.isnull().mean() * 100, # Porcentagem de valores nulos
    'unique_values': dataset_airbnb.nunique()           # Contagem de valores únicos
                    })

print(nulos)

"""
Com base na tabela acima podemos ver que as variáveis 'bathrooms' e 'calendar_update' não apresentam qualquer valor e a variável 'scrape_id' tem apenas um valor único. Como tal terão de ser removidas do nosso dataset.

Para além disso existem variáveis que apresentam apenas 2 valores únicos, como é o caso de 'last_scraped', 'source', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'calendar_last_scraped' e 'instant_bookable'.

"""

dataset_airbnb[['last_scraped', 'source', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'calendar_last_scraped', 'instant_bookable']].head(15)

# Lista das variáveis binárias
variaveis_binarias = ['last_scraped', 'source', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'calendar_last_scraped', 'instant_bookable']

# Define o número de colunas para exibir os gráficos
num_colunas = 2

# Calcula o número de linhas necessário com base no número de variáveis
num_linhas = (len(variaveis_binarias) + num_colunas - 1) // num_colunas

# Cria uma figura com subplots
fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(10, 20))

# Loop pelas variáveis binárias e cria os gráficos de barras
for i, var in enumerate(variaveis_binarias):
    linha = i // num_colunas
    coluna = i % num_colunas
    ax = axs[linha, coluna]

    # Contagem dos valores
    counts = dataset_airbnb[var].value_counts()

    # Cria o gráfico de barras
    ax = counts.plot(kind='bar', ax=ax, color=['skyblue', 'salmon'])

    # Adiciona anotações com os valores acima das barras
    for p in ax.patches:
        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')

    # Configurações do gráfico
    ax.set_title(f'Distribuição de {var}')
    ax.set_xlabel(var)
    ax.set_ylabel('Contagem')

# Remove subplots vazios, se houverem
if len(variaveis_binarias) % 2 != 0:
    fig.delaxes(axs[num_linhas - 1, 1])

# Ajusta o layout para evitar sobreposição
plt.tight_layout()

# Mostra os gráficos
plt.show()

"""Posso remover estas colunas uma vez que têm uma distribuição uniforme o que as torna irrelevantes para a análise de previsão de preços.

Vamos agora remover todas as variáveis que até ao momento determinámos como não sendo necessárias para a análise em questão
"""

dataset_airbnb.drop(columns=['last_scraped', 'source', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'calendar_last_scraped', 'instant_bookable', 'bathrooms', 'calendar_updated'],inplace=True)

dataset_airbnb.info()

"""Do nosso conjunto de variáveis do dataset sabemos que as variáveis que são URL não irão ser utilizadas para previsão de preço.
Deste modo iremos retirar as seguintes colunas:
  'id', 'listing_url', 'scrape_id', 'picture_url', 'host_id', 'host_url','host_thumbnail_url' e 'host_picture_url'  
"""

dataset_airbnb.drop(columns=['id', 'listing_url', 'scrape_id', 'picture_url', 'host_id', 'host_url','host_thumbnail_url', 'host_picture_url'],inplace=True)

dataset_airbnb.info()

dataset_airbnb.head()

"""# Remover nulos"""

# Criar um DataFrame com valores nulos, tipos de dados e contagem de valores únicos
nulos = pd.DataFrame({
    'null_values': dataset_airbnb.isnull().mean() * 100, # Porcentagem de valores nulos
    'unique_values': dataset_airbnb.nunique()           # Contagem de valores únicos
                    })

print(nulos)

"""Para uma análise mais precisa irei retirar todas colunas com valores nulos >=15%.
Deste modo iremos fazer drop das colunas: 'neighborhood_overview', 'host_location', 'host_about', 'host_neighbourhood' e 'neighbourhood'
"""

dataset_airbnb.drop(columns=['neighborhood_overview', 'host_location', 'host_about', 'host_neighbourhood', 'neighbourhood'],inplace=True)

# Criar um DataFrame com valores nulos, tipos de dados e contagem de valores únicos
nulos = pd.DataFrame({
    'null_values': dataset_airbnb.isnull().mean() * 100, # Porcentagem de valores nulos
    'unique_values': dataset_airbnb.nunique()           # Contagem de valores únicos
                    })

print(nulos)

"""Para as restantes variáveis que têm valores nulos < 15% iremos apenas fazer eliminação de linhas e não da coluna inteira"""

# Eliminar linhas com valores nulos
dataset_airbnb = dataset_airbnb.dropna()

# Opcional: redefinir o índice
dataset_airbnb = dataset_airbnb.reset_index(drop=True)

# Criar um DataFrame com valores nulos, tipos de dados e contagem de valores únicos
nulos = pd.DataFrame({
    'null_values': dataset_airbnb.isnull().mean() * 100, # Porcentagem de valores nulos
    'unique_values': dataset_airbnb.nunique()           # Contagem de valores únicos
                    })

print(nulos)

# Dimensão do Dataset
print(f'number of rows: {dataset_airbnb.shape[0]}')
print(f'number of columns: {dataset_airbnb.shape[1]}')

"""Como não vamos dar uso de qualquer técnica de Neuro-linguistic Programming or NLP podemos fazer drop das colunas 'name' e 'description'"""

dataset_airbnb.drop(columns=['name', 'description', 'host_name'],inplace=True)

dataset_airbnb.info()

"""# Variáveis identicas

minimum_nights, maximum_nights, minimum_minimum_nights, maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights, minimum_nights_avg_ntm, maximum_nights_avg_ntm

É necessário analisar mas aparenta ter a mesma informação
"""

dataset_airbnb[['minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',
'minimum_maximum_nights', 'maximum_maximum_nights','minimum_nights_avg_ntm', 'maximum_nights_avg_ntm']].head(20)

"""Posto isto vamos apenas manter minimum_nights e maximum_night e eliminar o resto"""

dataset_airbnb.drop(columns=['minimum_minimum_nights', 'maximum_minimum_nights',
'minimum_maximum_nights', 'maximum_maximum_nights','minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'],inplace=True)

dataset_airbnb.head()

dataset_airbnb.info()

"""->host_response_rate; host_acceptance_rate

->host_listings_count; host_total_listings_count; calculated_host_listings_count; calculated_host_listings_count_entire_homes; calculated_host_listings_count_private_rooms; calculated_host_listings_count_shared_rooms

->neighbourhood_cleansed; neighbourhood_group_cleansed; latitude; longitude

 * **
->availability_30; availability_60; availability_90; availability_365

->number_of_reviews; number_of_reviews_ltm; number_of_reviews_l30d**


"""

dataset_airbnb['host_response_rate'] = dataset_airbnb['host_response_rate'].str.rstrip('%').astype(float) / 100
dataset_airbnb['host_acceptance_rate'] = dataset_airbnb['host_acceptance_rate'].str.rstrip('%').astype(float) / 100

dataset_airbnb.dtypes

display(dataset_airbnb[['host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms']].head(50))

"""Vou deixar apenas a coluna calculated_host_listings_count"""

dataset_airbnb.drop(columns=['host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms'],inplace=True)

display(dataset_airbnb[['neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude']].head(50))

"""Com base na tabela percebemos que a coluna neighbourhood_group_cleansed não acrescenta muita informação. Como tal, vamos retirar esta coluna do nosso dataset

"""

dataset_airbnb.drop(columns=['neighbourhood_group_cleansed'],inplace=True)

dataset_airbnb.dtypes

"""# Converter data types

Vamos agora converter todos as variáveis objeto para um tipo de dados admissivel para correr modelos de previsão

-> host_since, host_response_time, host_verifications, property_type, room_type, bathrooms_text, amenities, price, first_review, last_review, license
"""

#Vamos converter todas as colunas de data para o tipo datatime

#Todas as colunas de data
colunas_de_data = ['host_since', 'first_review', 'last_review']

# Use um loop para converter cada coluna de data
for coluna in colunas_de_data:
    dataset_airbnb[coluna] = pd.to_datetime(dataset_airbnb[coluna])

display(dataset_airbnb[['host_since', 'first_review', 'last_review']].head(50))

display(dataset_airbnb[['host_response_time', 'host_verifications', 'property_type', 'room_type', 'bathrooms_text', 'amenities', 'price', 'license']].head(50))

"""Vamos fazer drop de host_verifications e license pois não tem qualquer utilidade para nós. Em relação ao preço retiramos o $ e a ',' e só depois convertemos para numérico. As restantes colunas terão que ser analisadas com mais cuidado"""

dataset_airbnb.drop(columns=['host_verifications', 'license'],inplace=True)

# Opcional: redefinir o índice se desejar
dataset_airbnb = dataset_airbnb.reset_index(drop=True)

dataset_airbnb.info()

# 1. Remova os caracteres especiais
dataset_airbnb['price'] = dataset_airbnb['price'].str.replace('[\$,]', '', regex=True)

# 2. Converta a coluna para o tipo numérico (float)
dataset_airbnb['price'] = pd.to_numeric(dataset_airbnb['price'], errors='coerce')

dataset_airbnb.info()

dataset_airbnb.host_response_time.value_counts(normalize=True)

import seaborn as sns
import matplotlib.pyplot as plt

# Calcular as contagens normalizadas dos valores na coluna "host_response_time"
response_time_counts = dataset_airbnb['host_response_time'].value_counts(normalize=True)

# Criar o gráfico de barras
plt.figure(figsize=(10, 6))  # Tamanho da figura
sns.barplot(x=response_time_counts.index, y=response_time_counts.values, palette="viridis")
plt.title('Distribuição de Tempo de Resposta do Anfitrião')
plt.xlabel('Tempo de Resposta do Anfitrião')
plt.ylabel('Porcentagem')
plt.xticks(rotation=45)  # Rotação dos rótulos do eixo x para melhor legibilidade

# Adicionar os valores de porcentagem no topo das barras
for i, v in enumerate(response_time_counts.values):
    plt.text(i, v, f'{v:.2%}', ha='center', va='bottom', fontsize=12)

# Mostrar o gráfico
plt.tight_layout()
plt.show()

"""A similar story is true for host_response_rate, with about a third of values being null. This will also be kept as its own category, after grouping other values into meaningful groups (i.e. transforming this into a categorical feature, rather than a numerical one). Because about 75% of hosts respond 100% of the time, this will be kept as its own category, and other values will be grouped into bins."""

dataset_airbnb.head()

# Selecione a coluna 'host_response_rate' e use describe
estatisticas = dataset_airbnb['host_response_rate'].describe()

# Exiba as estatísticas resumidas
print(estatisticas)

import seaborn as sns
import matplotlib.pyplot as plt

# Crie um boxplot para 'host_response_rate'
plt.figure(figsize=(8, 6))
sns.boxplot(x='host_response_rate', data=dataset_airbnb)

# Adicione rótulo ao eixo x
plt.xlabel('Host Response Rate')

# Mostre o gráfico
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Criar intervalos de 0.20
bins = [0, 0.20, 0.40, 0.60, 0.80, 1.00]

# Rotule os intervalos
labels = ['0-0.20', '0.20-0.40', '0.40-0.60', '0.60-0.80', '0.80-1.00']

# Crie um gráfico de barras diretamente com os intervalos
plt.figure(figsize=(10, 6))
sns.histplot(data=dataset_airbnb, x='host_response_rate', bins=bins, palette='viridis')

# Adicione rótulos ao eixo x e y
plt.xlabel('Host Response Rate')
plt.ylabel('Count')

# Rotacione os rótulos do eixo x para facilitar a leitura
plt.xticks(rotation=45)

# Mostre o gráfico
plt.show()

# Criar intervalos de 0.20
bins = [0, 0.20, 0.40, 0.60, 0.80, 1.00]

# Rotule os intervalos
labels = ['0-0.20', '0.20-0.40', '0.40-0.60', '0.60-0.80', '0.80-1.00']

# Criar um gráfico de barras para host_response_rate
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.histplot(data=dataset_airbnb, x='host_response_rate', bins=bins, palette='viridis')

# Adicionar rótulos ao eixo x e y
plt.xlabel('Host Response Rate')
plt.ylabel('Count')
plt.title('Host Response Rate')

# Rotacionar os rótulos do eixo x para facilitar a leitura
plt.xticks(rotation=45)

# Criar um gráfico de barras para host_acceptance_rate
plt.subplot(1, 2, 2)
sns.histplot(data=dataset_airbnb, x='host_acceptance_rate', bins=bins, palette='viridis')

# Adicionar rótulos ao eixo x e y
plt.xlabel('Host Acceptance Rate')
plt.ylabel('Count')
plt.title('Host Acceptance Rate')

# Rotacionar os rótulos do eixo x para facilitar a leitura
plt.xticks(rotation=45)

# Ajustar a posição dos gráficos
plt.tight_layout()

# Mostrar os gráficos
plt.show()

dataset_airbnb

"""Some cleaning of property types is required as there are a large number of categories with only a few listings. The categories Apartment, House, Room and Shared Room and Other will be used, as most properties can be classified as either apartment ,house or room."""

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

"""# Property type e Room type"""

display(dataset_airbnb.property_type.value_counts())

display(dataset_airbnb.room_type.value_counts())

"""Devido à elevada diversidade de tipos de propriedade vamos manter a nossa análise restringida ao tipo de quarto. Deste modo não vamos precisar da coluna property_type"""

dataset_airbnb.drop(columns=['property_type'],inplace=True)

"""Checking whether boolean and categorical features contain sufficient numbers of instances in each category to make them worth including"""

# Replacing columns with f/t with 0/1
dataset_airbnb.replace({'f': 0, 't': 1}, inplace=True)

# Plotting the distribution of numerical and boolean categories
dataset_airbnb.hist(figsize=(30,30));

dataset_airbnb.shape

"""host_response_time, Host_response_rate e host_acceptance_rate estão muito agrupados no 1. O que torna estas duas variáveis irrelevantes. Vamos fazer drop

*host_since* is a datetime column, and will be converted into a measure of the number of days that a host has been on the platform, measured from the date that the data was scraped (September 10, 2022). The original column will be left in initially for EDA, and dropped later.
"""

dataset_airbnb.drop(columns=['host_response_rate', 'host_acceptance_rate', 'host_response_time'],inplace=True)

#Já convertemos as colunas 'host_since', 'first_review', 'last_review' para DateTime

# Calculating the number of days
#dataset_airbnb['host_days_active'] = (pd.datetime(2022, 9, 10) - dataset_airbnb.host_since).astype('timedelta64[D]')

# Printing mean and median
#print("Mean days as host:", round(dataset_airbnb['host_days_active'].mean(),0))
#print("Median days as host:", dataset_airbnb['host_days_active'].median())

# Replacing null values with the median
#dataset_airbnb.host_days_active.fillna(dataset_airbnb.host_days_active.median(), inplace=True)

dataset_airbnb.info()

# lets have a lool where stand with our null values
total_nan = dataset_airbnb.isna().sum().sort_values(ascending=False)
percentage_nan = (total_nan / dataset_airbnb.shape[0]) * 100
tabel = pd.concat([total_nan, percentage_nan], axis=1, keys=['Total NaN values', 'Percentage of NaN values'])
tabel

# Resetting the index as we deleted some rows
dataset_airbnb.reset_index(drop=True, inplace=True)

"""`Amenities-NLP`

# Price
"""

fig = plt.figure(figsize =(5, 5))

# Creating plot
plt.boxplot(dataset_airbnb['price'])

# show plot
plt.show()

"""# Observations:
 -Longitude, accomodates, availability_90 Latitude are the only attributes that are not badly skewed.

  - Our target Vector in particular is highly positively skewed and needs attention.

  - They all seem to have a lot of outliers.

  - Bathrooms, , beds, bedrooms are positively correlated with the price.

Price cap is clearly visible at 10,000, but it shouldn't be a problem for us as we will be filtering out such expensive night stays for our model to predict well.

There are straight lines visible in the bathroom scatter plot as well.
"""

# Finding skewness of the following attributes
cols = ['longitude', 'latitude','price',  'bedrooms', 'beds', 'accommodates', 'maximum_nights', 'minimum_nights','review_scores_accuracy','number_of_reviews',
       'reviews_per_month','availability_30','availability_60','availability_365','review_scores_communication','calculated_host_listings_count']
def finding_skewness():
    for col in cols:
        print(f'{col} has a skewness of {dataset_airbnb[col].skew(skipna = True)}')

finding_skewness()

"""Price as our target variable with a skewness of 28.71 it could be a huge problem. We could do the following to fix the problem:

- we could filter out the outliers carefully looking at the box plot
- we could also take the log of price to further bring down the skewness
"""

# Suponha que você queira criar um boxplot da coluna 'price' em seu DataFrame 'airbnb'
plt.figure(dpi=250, facecolor='#dadada', figsize=(30, 10))

sns.boxplot(x=dataset_airbnb['price'], palette='Blues')
#plt.ylim(-5000, 5000)  # Defina o limite do eixo y, se necessário

# Remova as bordas indesejadas
plt.gca().spines["top"].set_visible(False)
plt.gca().spines["bottom"].set_visible(False)
plt.gca().spines["right"].set_visible(False)
plt.gca().spines["left"].set_visible(False)

plt.savefig(r"box2.png")

plt.show()

"""Its hard to believe that a nightly price of an airbnb would go all the way up to 12000. In short there are a lot of outliers in price that could really throw off our predictions"""

plt.figure(dpi=250, facecolor = '#dadada')
# by limitting the x axis we are no able to see the box
sns.boxplot(x=dataset_airbnb['price'], data=dataset_airbnb, palette='Blues')
plt.xlim(0,2300)

# Remove the splines
plt.gca().spines["top"].set_visible(False)
plt.gca().spines["bottom"].set_visible(False)
plt.gca().spines["right"].set_visible(False)
plt.gca().spines["left"].set_visible(False)

plt.savefig(r"box1.png")

plt.show()

"""
Looking at the box plot interquartile range of airbnb nightly price is between 49 to 110, and about 98 is the mean."""

# Selecione a coluna 'host_response_rate' e use describe
estatisticas = dataset_airbnb['price'].describe()

# Exiba as estatísticas resumidas
print(estatisticas)

# checking how much did we control the skewness on price
dataset_airbnb.price.skew()

#Limpar os outliers

dataset_airbnb = dataset_airbnb[(dataset_airbnb['price'] >= 20) & (dataset_airbnb['price'] <= 220)]

# checking how much did we control the skewness on price
dataset_airbnb.price.skew()

"""We were able to bring down the skewness of our target variable down to 4.18 from 28.71 and the rest we will take care by applying log later."""

import seaborn as sns
import matplotlib.pyplot as plt

def plotting_to_check_skewness():
    col = 'price'

    # Create a figure with subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4), dpi=100)

    # Plot a histogram with more bins
    sns.histplot(dataset_airbnb[col], kde=True, bins=50, ax=ax1)

    # Add labels and title
    ax1.set_xlabel(col)
    ax1.set_ylabel('Frequency')
    ax1.set_title(f'Distribution of {col}')

    # Plot a box plot to visualize outliers
    sns.boxplot(x=dataset_airbnb[col], ax=ax2)

    # Add labels and title
    ax2.set_xlabel(col)
    ax2.set_title(f'Box Plot of {col}')

    # Display mean and median values
    mean_val = dataset_airbnb[col].mean()
    median_val = dataset_airbnb[col].median()
    ax2.text(0.05, 0.85, f'Mean: {mean_val:.2f}', transform=ax2.transAxes)
    ax2.text(0.05, 0.75, f'Median: {median_val:.2f}', transform=ax2.transAxes)

    # Remove the splines
    for ax in [ax1, ax2]:
        ax.spines["top"].set_visible(False)
        ax.spines["right"].set_visible(False)

    plt.tight_layout()
    plt.show()

plotting_to_check_skewness()

"""# Bathroom text"""

# Obter os valores únicos da coluna 'bathrooms'
unique_bathrooms = dataset_airbnb['bathrooms_text'].unique()

# Vamos imprimir os valores únicos
print(unique_bathrooms)

# Filtrar o DataFrame para manter apenas as linhas com 'room_type' igual a 'Shared room'
shared_room_df = dataset_airbnb[dataset_airbnb['room_type'] == 'Shared room']

# Exibir os valores únicos da coluna 'bathroom_text' no DataFrame filtrado
unique_bathrooms_values = shared_room_df['bathrooms_text'].unique()

# Imprimir os valores únicos
print(unique_bathrooms_values)

# Filtrar o DataFrame para manter apenas as linhas com 'room_type' igual a 'Shared room'
shared_room_df = dataset_airbnb[dataset_airbnb['room_type'] == 'Private room']

# Exibir os valores únicos da coluna 'bathroom_text' no DataFrame filtrado
unique_bathrooms_values = shared_room_df['bathrooms_text'].unique()

# Imprimir os valores únicos
print(unique_bathrooms_values)

"""Vou apenas manter o número e retirar a informação quanto ao tipo de casa de banho"""

# Criar uma nova coluna 'bathrooms' com os números extraídos de 'bathroom_text'
dataset_airbnb['bathrooms'] = dataset_airbnb['bathrooms_text'].str.extract(r'(\d+\.*\d*)').astype(float)

# Substituir valores vazios (NaN) por 0.5
dataset_airbnb['bathrooms'].fillna(0.5, inplace=True)

# Remover a coluna 'bathroom_text' do DataFrame
dataset_airbnb.drop(columns=['bathrooms_text'], inplace=True)

# Exibir o DataFrame resultante
print(dataset_airbnb[['bathrooms']].head(20))

# Obter os valores únicos da coluna 'bathrooms'
unique_bathrooms = dataset_airbnb['bathrooms'].unique()

# Vamos imprimir os valores únicos
print(unique_bathrooms)

dataset_airbnb.dtypes
dataset_airbnb.head()

dataset_airbnb.info()

"""#Amenities

"""

unique_amenities_values = dataset_airbnb['amenities'].unique()
print(unique_amenities_values)

pip install wordcloud

import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Supondo que você tenha uma coluna 'amenities' no seu DataFrame 'dataset_airbnb'
amenities_list = dataset_airbnb['amenities'].str.replace('[{}""]', '').str.split(',')

all_amenities = ' '.join([amenity for sublist in amenities_list for amenity in sublist])

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_amenities)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt

all_words = [word for sublist in amenities_list for word in sublist]

word_counts = Counter(all_words)

top_words_df = pd.DataFrame(word_counts.most_common(20), columns=['Palavra', 'Contagem'])

plt.figure(figsize=(12, 6))
plt.barh(top_words_df['Palavra'], top_words_df['Contagem'], color='skyblue')
plt.xlabel('Contagem')
plt.ylabel('Palavra')
plt.title('Palavras Mais Utilizadas em Amenities')
plt.gca().invert_yaxis()
plt.show()

from collections import Counter

# Supondo que você tenha uma coluna 'amenities' no seu DataFrame 'dataset_airbnb'
amenities_list = dataset_airbnb['amenities'].str.replace('[{}""]', '').str.split(',')

# Criar uma lista plana de todas as palavras em 'amenities'
all_amenities = [word for sublist in amenities_list for word in sublist]

# Usar Counter para contar a frequência de cada amenidade
amenities_counts = Counter(all_amenities)

# Classificar as amenidades em ordem crescente de frequência
sorted_amenities = sorted(amenities_counts.items(), key=lambda x: x[1])

# Exibir as amenidades menos usadas (por exemplo, as 10 primeiras)
least_used_amenities = sorted_amenities[:10]

for amenity, count in least_used_amenities:
    print(f"Amenidade: {amenity}, Frequência: {count}")

# Supondo que você tenha uma coluna 'amenities' no seu DataFrame 'dataset_airbnb'
amenities_list = dataset_airbnb['amenities'].str.replace('[{}""]', '').str.split(',')

# Criar uma lista plana de todas as palavras em 'amenities'
all_amenities = [word for sublist in amenities_list for word in sublist]

# Usar o set para obter amenidades únicas e, em seguida, contar quantas são únicas
unique_amenities = set(all_amenities)
total_unique_amenities = len(unique_amenities)

# Exibir o total de amenidades únicas
print("Total de amenidades únicas:", total_unique_amenities)

from collections import Counter

# Supondo que você tenha uma coluna 'amenities' no seu DataFrame 'dataset_airbnb'
amenities_list = dataset_airbnb['amenities'].str.replace('[{}""]', '').str.split(',')

# Criar uma lista plana de todas as palavras em 'amenities'
all_amenities = [word for sublist in amenities_list for word in sublist]

# Usar Counter para contar a frequência de cada amenidade
amenities_counts = Counter(all_amenities)

# Contar quantas amenidades diferentes têm frequência inferior a 3000
amenities_below_3000 = sum(1 for count in amenities_counts.values() if count < 3000)

print(f"Quantidade de amenidades diferentes com frequência inferior a 3000: {amenities_below_3000}")

"""Não faz sentido incorporar um amenity que quase nunca é utilizado. Deste modo não vamos considerar os que tem uma frequência inferior a 3000. Por outro lado também não vamos admitir um amenity que se repita em práticamente todos os casos.
E portanto tendo em conta estes fatores e com base em pesquisa e experiência pessoal iremos selecionar os amenities que mais impacto poderão ter no preço
"""

import pandas as pd
from collections import Counter

# Suponha que você tenha uma coluna 'amenities' no seu DataFrame 'dataset_airbnb'
amenities_list = dataset_airbnb['amenities'].str.replace('[{}""]', '').str.split(',')

# Criar uma lista plana de todas as palavras em 'amenities'
all_words = [word for sublist in amenities_list for word in sublist]

# Contar a frequência de cada palavra
word_counts = Counter(all_words)

# Criar um DataFrame com todas as palavras e suas contagens
word_counts_df = pd.DataFrame(word_counts.items(), columns=['Amenity', 'Count'])

# Classificar o DataFrame pela contagem em ordem decrescente
sorted_word_counts_df = word_counts_df.sort_values(by='Count', ascending=False)

# Exibir a lista completa dos 42 amenities mais comuns
top_42_amenities = sorted_word_counts_df.head(42)
print(top_42_amenities)

# Verifique se a coluna 'amenities' contém as palavras-chave
dataset_airbnb['Air conditioning'] = dataset_airbnb['amenities'].str.contains('Air conditioning').astype(int)
dataset_airbnb['TV'] = dataset_airbnb['amenities'].str.contains('TV').astype(int)
dataset_airbnb['Extra pillows and blankets'] = dataset_airbnb['amenities'].str.contains('Extra pillows and blankets').astype(int)
dataset_airbnb['Heating'] = dataset_airbnb['amenities'].str.contains('Heating').astype(int)

# Remova a coluna 'amenities'
dataset_airbnb.drop(columns=['amenities'], inplace=True)

dataset_airbnb.head()

"""# Correlations"""

# Calculate the correlation matrix
correlation_matrix = dataset_airbnb.corr()

# Set the size of each cell in the heatmap
sns.set(rc={'figure.figsize':(20,16)})

# Create a heatmap with larger squares
plt.figure(figsize=(20, 16))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", cbar_kws={'shrink': 0.7})

# Set the title of the plot
plt.title('Correlation Heatmap')

# Show the plot
plt.show()

"""Com base na matrix de correlação iremos fazer drop de variáveis que apresentam um elevado grau de correlação.

As camas, os quartos e o número de pessoas que uma propriedade acomoda estão altamente correlacionados. O número de pessoas acomodadas tem sido tradicionalmente um parâmetro de pesquisa de maior prioridade na Airbnb, uma vez que é mais relevante para quartos privados e partilhados do que o número de quartos
"""

dataset_airbnb.drop(columns=['beds', 'bedrooms'],inplace=True)

"""Dos três disponibilidade_30, disponibilidade_60, disponibilidade_90, dois também poderiam ser suprimidos, uma vez que estão altamente correlacionados entre si"""

dataset_airbnb.drop(columns=['availability_60', 'availability_90'],inplace=True)

"""Areas of multi-collinearity:
                                                                            
- There are strong negative correlations between property_type_House and property_type_Apartment, and between room_type_Private room and room_type_Entire_home_apt (as these were the main two categories of their features before they were one-hot encoded). Although these are important categories, one of each will be dropped in order to reduce multi-collinearity (apartments and private rooms, as these are the second most common categories).

`review ratings columns`
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style
sns.set(style="whitegrid")

# List of review rating columns
review_rating_columns = [
    'review_scores_rating',
    'review_scores_accuracy',
    'review_scores_cleanliness',
    'review_scores_checkin',
    'review_scores_communication',
    'review_scores_location',
    'review_scores_value'
]

# Create subplots with one row and multiple columns
fig, axes = plt.subplots(1, len(review_rating_columns), figsize=(25, 6))
fig.tight_layout()

# Define the custom bins
custom_bins = [0, 3, 4, 5]

# Plot histograms for each review rating column with custom bins and styling
for i, col in enumerate(review_rating_columns):
    ax = axes[i]
    sns.histplot(dataset_airbnb[col].dropna(), bins=custom_bins, ax=ax, color='skyblue', edgecolor='black')
    ax.set_title(col)
    ax.set_xlabel('Value')
    ax.set_ylabel('')
    ax.set_xticks([1.5, 3.5, 4.5])
    ax.set_xticklabels(['0-3', '3-4', '4-5'])

plt.show()

dataset_airbnb.drop(columns=['review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_value'],inplace=True)

# Resetting the index as we deleted some rows
dataset_airbnb.reset_index(drop=True, inplace=True)

# Calculate the correlation matrix
correlation_matrix = dataset_airbnb.corr()

# Set the size of each cell in the heatmap
sns.set(rc={'figure.figsize':(20,16)})

# Create a heatmap with larger squares
plt.figure(figsize=(20, 16))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", cbar_kws={'shrink': 0.7})

# Set the title of the plot
plt.title('Correlation Heatmap')

# Show the plot
plt.show()

"""# Guardar o dataset"""

dataset_airbnb.info()

dataset_airbnb.to_csv('Recolha e tratamento da base de dados.csv', index=False)

# Para criar um link de download para o arquivo CSV
from google.colab import files

files.download('Recolha e tratamento da base de dados.csv')